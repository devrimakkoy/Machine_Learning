{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Data Preprocessing\n",
    "How are we going to preprocess our images? First, we will apply some transformations on all the images of the training set. The reason why we will apply some transformations on the images of the training set is to avoid overfitting. What are these transformations? Some simple “geometrical transformations” or some zooms or rotations on our images. These transformations are called “image augmentation”. Which consists of transforming our images of the training set so that our CNN model does not over learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocesiing the Training Set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True)\n",
    "#Now we will connect this train_datagen object to our training set images;\n",
    "training_set = train_datagen.flow_from_directory('dataset\\\\training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the Test Set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset\\\\test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 – Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 – Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 – Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 – Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 – Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 144s 570ms/step - loss: 0.6851 - accuracy: 0.5566 - val_loss: 0.6613 - val_accuracy: 0.6115\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.6365 - accuracy: 0.6369 - val_loss: 0.6017 - val_accuracy: 0.6835\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 69s 277ms/step - loss: 0.5914 - accuracy: 0.6781 - val_loss: 0.5641 - val_accuracy: 0.7065\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.5568 - accuracy: 0.7104 - val_loss: 0.5708 - val_accuracy: 0.7135\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 68s 270ms/step - loss: 0.5385 - accuracy: 0.7269 - val_loss: 0.5256 - val_accuracy: 0.7440\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 66s 262ms/step - loss: 0.5141 - accuracy: 0.7477 - val_loss: 0.5184 - val_accuracy: 0.7420\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 71s 285ms/step - loss: 0.4985 - accuracy: 0.7550 - val_loss: 0.4995 - val_accuracy: 0.7565\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 68s 270ms/step - loss: 0.4689 - accuracy: 0.7728 - val_loss: 0.4975 - val_accuracy: 0.7510\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.4589 - accuracy: 0.7809 - val_loss: 0.5340 - val_accuracy: 0.7385\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 67s 266ms/step - loss: 0.4487 - accuracy: 0.7840 - val_loss: 0.4889 - val_accuracy: 0.7635\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 66s 262ms/step - loss: 0.4329 - accuracy: 0.8005 - val_loss: 0.4974 - val_accuracy: 0.7595\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.4164 - accuracy: 0.8060 - val_loss: 0.4805 - val_accuracy: 0.7975\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 64s 255ms/step - loss: 0.3991 - accuracy: 0.8140 - val_loss: 0.4974 - val_accuracy: 0.7885\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 71s 286ms/step - loss: 0.3874 - accuracy: 0.8229 - val_loss: 0.5035 - val_accuracy: 0.7775\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 64s 256ms/step - loss: 0.3684 - accuracy: 0.8341 - val_loss: 0.5020 - val_accuracy: 0.7835\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 52s 210ms/step - loss: 0.3537 - accuracy: 0.8424 - val_loss: 0.4782 - val_accuracy: 0.7820\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 70s 281ms/step - loss: 0.3383 - accuracy: 0.8475 - val_loss: 0.4944 - val_accuracy: 0.7910\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 71s 282ms/step - loss: 0.3199 - accuracy: 0.8637 - val_loss: 0.5272 - val_accuracy: 0.7800\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 61s 244ms/step - loss: 0.2965 - accuracy: 0.8754 - val_loss: 0.5401 - val_accuracy: 0.7730\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.2913 - accuracy: 0.8748 - val_loss: 0.5565 - val_accuracy: 0.7840\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 71s 282ms/step - loss: 0.2797 - accuracy: 0.8823 - val_loss: 0.5411 - val_accuracy: 0.7930\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 73s 291ms/step - loss: 0.2549 - accuracy: 0.8939 - val_loss: 0.6160 - val_accuracy: 0.7645\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 64s 258ms/step - loss: 0.2426 - accuracy: 0.9004 - val_loss: 0.5607 - val_accuracy: 0.7895\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.2413 - accuracy: 0.8989 - val_loss: 0.5688 - val_accuracy: 0.7880\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 49s 194ms/step - loss: 0.2158 - accuracy: 0.9114 - val_loss: 0.5935 - val_accuracy: 0.7860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a386895300>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the CNN on the Training set and evaluating it on the Test set\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - Making a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = tf.keras.utils.load_img('dataset\\single_prediction\\cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95bf662a0931fbd27bd34f8a2e8af46f3fcd2c2c74774049b8f3cb839e48506f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
